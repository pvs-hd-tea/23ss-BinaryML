# This file is to calculate the statistics of the prediction performance of the model.
# The output console log file of the individual prediction function should be passed as the input to this file in "document_path"

# Specify the path to your text document
document_path = "./logs/individual_prediction_output.txt"

# Initialize a dictionary to store the extracted information
predictions = {}

# Open the document and read its lines
with open(document_path, "r") as file:
    lines = file.readlines()

# Initialize variables to track current prediction information
current_file = None
current_correctness = None
current_prediction = None
current_actual = None

# Initialize dictionaries to store counts and rates per CWE code
cwe_counts = {}
cwe_rates = {}

# Iterate through every 9th line (0-based index)
for i in range(8, len(lines), 9):
    line = lines[i].strip()  # Remove leading/trailing spaces and newline characters

    # Extract the file name
    parts = line.split("'")
    if len(parts) >= 2:
        file_name = parts[1]

        # Extract the CWE code from the file name (e.g., CWE546)
        cwe_parts = file_name.split("_")
        if len(cwe_parts) >= 1:
            cwe_code = cwe_parts[0]

        # Extract whether the prediction is correct/incorrect and benign/vulnerable
        if " correctly predicted as Benign file" in line:
            current_correctness = "Correct"
            current_prediction = "Benign"
        elif " incorrectly predicted as Vulnerable file" in line:
            current_correctness = "Incorrect"
            current_prediction = "Vulnerable"
        elif " correctly predicted as Vulnerable file" in line:
            current_correctness = "Correct"
            current_prediction = "Vulnerable"
        elif " incorrectly predicted as Benign file" in line:
            current_correctness = "Incorrect"
            current_prediction = "Benign"

        # Compute the actual file type based on the provided rules
        if current_correctness == "Correct":
            current_actual = current_prediction
        else:
            current_actual = "Benign" if current_prediction == "Vulnerable" else "Vulnerable"

        # Store the information in the dictionary
        predictions[file_name] = {
            "Correctness": current_correctness,
            "Prediction": current_prediction,
            "Actual": current_actual
        }

        # Update counts per CWE code
        if cwe_code not in cwe_counts:
            cwe_counts[cwe_code] = {
                "Total": 0,
                "Correct": 0,
                "Incorrect": 0
            }

        cwe_counts[cwe_code]["Total"] += 1
        if current_correctness == "Correct":
            cwe_counts[cwe_code]["Correct"] += 1
        else:
            cwe_counts[cwe_code]["Incorrect"] += 1

# Import the PrettyTable library
from prettytable import PrettyTable

# Create a list of unique CWE codes
unique_cwe_codes = list(set(cwe_code for cwe_code in cwe_counts.keys()))

# ... (previous code)

# Create a PrettyTable for CWE statistics
cwe_stats_table = PrettyTable()
cwe_stats_table.field_names = ["CWE Code", "Total Files", "Correctly Predicted", "Incorrectly Predicted"]

# Sort CWE codes by the number of incorrectly predicted files (descending order)
sorted_cwe_counts = sorted(cwe_counts.items(), key=lambda x: x[1]["Incorrect"], reverse=True)

# Populate the table with CWE statistics
for cwe_code, cwe_data in sorted_cwe_counts:
    total_files = cwe_data["Total"]
    correctly_predicted = cwe_data["Correct"]
    incorrectly_predicted = cwe_data["Incorrect"]
    cwe_stats_table.add_row([cwe_code, total_files, correctly_predicted, incorrectly_predicted])

# Calculate the totals for each column
total_total_files = sum([cwe_data["Total"] for cwe_code, cwe_data in sorted_cwe_counts])
total_correctly_predicted = sum([cwe_data["Correct"] for cwe_code, cwe_data in sorted_cwe_counts])
total_incorrectly_predicted = sum([cwe_data["Incorrect"] for cwe_code, cwe_data in sorted_cwe_counts])

# Add the row for column totals
cwe_stats_table.add_row(["Total", total_total_files, total_correctly_predicted, total_incorrectly_predicted])

# Print the CWE statistics table
print("CWE Statistics (Sorted by Incorrectly Predicted Files):")
print(cwe_stats_table)

# ... (rest of the code)


# Initialize variables for the confusion matrix
true_positive = 0
true_negative = 0
false_positive = 0
false_negative = 0

# Calculate confusion matrix values
for file_name, info in predictions.items():
    actual = info["Actual"]
    prediction = info["Prediction"]
    correctness = info["Correctness"]

    if correctness == "Correct":
        if actual == "Benign" and prediction == "Benign":
            true_positive += 1
        elif actual == "Vulnerable" and prediction == "Vulnerable":
            true_negative += 1
    else:
        if actual == "Benign" and prediction == "Vulnerable":
            false_positive += 1
        elif actual == "Vulnerable" and prediction == "Benign":
            false_negative += 1

# Create a pretty table for the confusion matrix
confusion_matrix = PrettyTable()
confusion_matrix.field_names = ["", "Predicted Benign", "Predicted Vulnerable"]
confusion_matrix.add_row(["Actual Benign", true_negative, false_positive])
confusion_matrix.add_row(["Actual Vulnerable", false_negative, true_positive])

# Print the confusion matrix
print("\nConfusion Matrix:")
print(confusion_matrix)

# # Calculate rates for TP, FP, TN, FN
# tp_rate = true_positive / (true_positive + false_negative)
# fp_rate = false_positive / (false_positive + true_negative)
# tn_rate = true_negative / (true_negative + false_positive)
# fn_rate = false_negative / (false_negative + true_positive)
#
# # Create a pretty table for TP, FP, TN, FN rates
# tp_fp_tn_fn_rates_table = PrettyTable()
# tp_fp_tn_fn_rates_table.field_names = ["Rate", "Value"]
# tp_fp_tn_fn_rates_table.add_row(["True Positive Rate (TPR)", f"{tp_rate:.2f}"])
# tp_fp_tn_fn_rates_table.add_row(["False Positive Rate (FPR)", f"{fp_rate:.2f}"])
# tp_fp_tn_fn_rates_table.add_row(["True Negative Rate (TNR)", f"{tn_rate:.2f}"])
# tp_fp_tn_fn_rates_table.add_row(["False Negative Rate (FNR)", f"{fn_rate:.2f}"])
#
# # Print TP, FP, TN, FN rates table
# print("\nRates for TP, FP, TN, FN:")
# print(tp_fp_tn_fn_rates_table)
