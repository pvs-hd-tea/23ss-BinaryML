import datetime

import torch

from binaryLoader import BinaryDataset, pad_collate_func


def printf(message):
    timestamp = datetime.datetime.now()
    timestamp_str = timestamp.strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp_str}] {message}")


def load_dataset(batch_size, max_seq_len=256, shuffle=True, num_workers=0):
    train_set = BinaryDataset(
        good_dir='/media/pavan/Dragon/Heidelberg University/Courses/Semester-2/AIPrak/Datasets/pe_machine_learning_dataset(passwordis_infected)/pe-machine-learning-dataset/bengin/',
        bad_dir='/media/pavan/Dragon/Heidelberg University/Courses/Semester-2/AIPrak/Datasets/pe_machine_learning_dataset(passwordis_infected)/pe-machine-learning-dataset/malware/',
        max_len=max_seq_len)

    # train_set = BinaryDataset(
    #     good_dir='/home/pavan/PycharmProjects/AI_prak_binary_ml/data/benign',
    #     bad_dir='/home/pavan/PycharmProjects/AI_prak_binary_ml/data/malware',
    #     max_len=max_seq_len)

    train_loader = torch.utils.data.DataLoader(train_set,
                                               batch_size=batch_size,
                                               shuffle=shuffle,
                                               num_workers=num_workers,
                                               collate_fn=pad_collate_func,
                                               drop_last=True)

    # test_set = BinaryDataset(
    #     good_dir='/home/pavan/PycharmProjects/AI_prak_binary_ml/data/benign',
    #     bad_dir='/home/pavan/PycharmProjects/AI_prak_binary_ml/data/malware',
    #     max_len=max_seq_len)

    test_set = BinaryDataset(
        good_dir='/media/pavan/Dragon/Heidelberg University/Courses/Semester-2/AIPrak/Datasets/pe_machine_learning_dataset(passwordis_infected)/pe-machine-learning-dataset/bengin/',
        bad_dir='/media/pavan/Dragon/Heidelberg University/Courses/Semester-2/AIPrak/Datasets/pe_machine_learning_dataset(passwordis_infected)/pe-machine-learning-dataset/malware/',
        max_len=max_seq_len)

    test_loader = torch.utils.data.DataLoader(test_set,
                                              batch_size=batch_size,
                                              shuffle=False,
                                              num_workers=num_workers,
                                              collate_fn=pad_collate_func,
                                              drop_last=True)

    return train_loader, test_loader


train, test = load_dataset(batch_size=128, max_seq_len=20, shuffle=True, num_workers=0)

for x, y in train:
    printf(type(x))
    printf(x.shape)
    printf(y.shape)
    printf(x)
    printf(y)
    break
